<p>
    On a trip back to India two years ago, I struck up a conversation with our
    helper Jayanthi. Jayanthi had been born into one of the oppressed castes in India. Her
    husband had vanished from her life, leaving her with her two daughters and
    not much else. She had been working in other people's homes,
    sweeping floors, washing clothes, and scrubbing dishes, ever since she was a teenager. That 
    had been her 'family profession'.
</p>
<p>
    One blistering afternoon, as an enormous ceiling fan was whirling over our
    heads, I asked Jayanthi if her daughters went to school. Perhaps to college even? 
    I asked, hoping for an affirmative.
</p>
<p>
    "No, ma," she said, "they are just girls. What are they going to do with
    school?"
</p>
<p>
    "Wouldn't you like her to go for an office job one day?" I asked.
</p>
<p>
    "No, that's never going to happen," she shook her head and dismissed the
    notion as though it were laughable as a unicorn in the middle of our living
    room.
</p>
<p>
    Later, as I lay on my mother-in-law's bed on fresh-smelling pillow, staring
    at the ceiling, I reflected on our chat. I valued education above most
    things in life. That's because I had the advantage of a father that
    believed in education - for boys AND girls. He himself had grown up in a
    family filled with scholars: one of his grandfathers was a local
    magistrate, and another was a doctor. Our family had been steeped in
    education for generations. Jayanthi did not share the same schemas and
    beliefs in her head that made learning essential to empowerment and
    progress in life. It was almost as though there were multiple little lakes
    in the jungle of life, and I got to swim in my lake with other educated
    people, and Jayanthi's family would never get to enter it. They simply
    didn't see the point even if they had the means. And some others like
    Jayanthi wanted to swim in this lake but had too many obstacles in their
    path toward it. Our differences could remain unbridged, perhaps even grow
    wider over time. I sighed about these harsh inequalities all around us as I
    went to sleep that night.
</p>
<p>
    This little encounter came into my head when I read a book about the use of
    data in mass decision-making systems and how that results in greater
    inequality in our society. The book is called "Weapons of Math
    Destruction", written by a self-styled 'math babe' Cathy O'Neill.
  </p>
  <br/><br/>

<img className="pb-5" src="https://thisisrajiraj.github.io/posts/images/weapons.jpg" 
    style="max-width: 50%;max-height: 50%"/>
<br/><br/>
  <p>
  In modern
    times, our mass decision-making algorithms decide many aspects of our lives
    and can bring greater fortune or greater ruin to individuals. They decide
    who gets a loan, who goes to top schools, who gets locked up in prison, who
    is hired for jobs, and so on. They often use <em>heuristics (</em>aka
    'rules of thumb') to make such judgements. These heuristics are coded in or
    learned by the machine from data. In either case, they are based on the
    belief that <em>the</em> <em>past predicts the future</em>. That is, if you
    have sinned in the past, you'll likely sin again. If you have failed tests
    before, you will fail again. If you have defaulted on a loan, you'll like
    do so again.
</p>
<br/>
<p>
    There are two problems with the use of such heuristics in our algorithms.
</p>
<p>
    1) It is not just you, the individual, on whom the bright radar of these
    algorithms falls. The algorithms try to predict your behavior based on
    behavior of people 'like you'. People from the same race as you, the same
    zip code as you, the same economic stratum as you. In his groundbreaking
    book, <em>Thinking Fast and Slow</em>, the behavioral scientist Daniel
    Kahneman calls this the 'representativeness heuristic'. We make judgements
    based on similarity __all the time__ . This pattern matching is not wholly
    pernicious. It helped our ancestors survive in the Savannahs. Our IQ tests
    judge us as intelligent if we can group similar objects based on abstract
    patterns all the time. But this heuristic can often lead us astray. It
    leads us to believe that a woman who has neatly styled hair, wearing bold
    lipstick and six-inch heels, does not fit the mold of a scientist. It can
    cause juries to pre-judge a black man guilty. It can cause school
    admissions officials to judge Jayanthi's daughter, living in her rickety
    shack in a squalid slum with illiterate parents, to be less likely to
succeed in their schools.    <strong>These are dangerous biases and stereotypes in our heads</strong>.
    Most people will steer away from them if they become aware of them. But
    when the sheathed in the erudition and opaqueness of our algorithms, we
    simply accept them as truths.
</p>
<p>
    2) These mass data systems <strong>miss the trees for the forest</strong>.
    Look at the image below. If I asked you what this picture is, you would
    probably say that it is a group of snowmen. You might be right in the 'big
    picture', but you also missed the lone panda lurking in there. (If you
    can't her, I will give you a hint at the end of this article.) In the
    forest of snowmen, most people miss the panda. But the panda exists and
    needs to be fed. Our data systems miss the lone pandas too. Often our data
    systems make decisions from aggregate wholes and miss the nuances of
    individuals in the group. For example, if a policy about the need of bamboo
    sticks was made based on the average of this picture, most likely the panda
    would not get her bamboo. That - indeed - would be sad.
</p>
<br/><br/>

<img className="pb-5" src="https://thisisrajiraj.github.io/posts/images/snoman.jpg" 
    style="max-width: 60%;max-height: 60%"/>
<br/><br/>
<p>
    The truth is that what applies to the sum may not apply to the constituent
    parts. Our mass data systems, however, ignore that. They aggregate data and
    present conclusions that human decision makers then turn around and apply
    to individuals. It becomes more pernicious when these algorithms are used
    at large scales of heterogenous people, do not use feedback loops to
    correct their mistaken inferences, and act as black boxes whose conclusions
    cannot be taken apart with reasoning.
</p>
<p>
    I live and breath data in my work. I have built multiple software systems
    that use intelligence to aid human decision-making. I am not against the
    use of data, far from it. In our modern lives, data helps us avoid
    congested roads when we drive. It prods us to pack an extra sweater for our
    trip abroad. It helps us understand what parts of the products we build are
    resonating with our customers, and what parts are not. It tells me that I
    should try Yuval Noah Harari's book next, because I have liked similar
    books in the past and my friends have liked his writing. Modern data
    systems have come to understand us as well as, or even better than, our
    dearest friends.
</p>
<p>
    But Cathy O'Neill is right. These data systems can make mistakes. And when
    they make mistakes at massive scales, the result may be as innocuous as one
    drenched and unhappy human who didn't take an umbrella with him. It may
    result in the erosion of our democracy, the widening of inequality, and the
    destruction of justice.
</p>
<p>
    Human societies have been riddled in inequality since pre-historic times.
    Jayanthi's station in life comes from centuries of oppression by one set of
    humans by another. But the arc of history has bent relentlessly toward
    justice. As we build our future, as we architect a world driven more and
    more by math, let's be cognizant of these biases in data. With great power
    comes great responsibility. Data and math are insanely powerful. Let us
    wield them responsibly.
</p>
<p>
    Here is the book
    <a href="https://www.amazon.com/dp/B019B6VCLO">
        Weapons of Math Destruction.
    </a>
     Check it out for yourself.
</p>
